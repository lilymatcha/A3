{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "# import CSV files as DataFrames\n",
    "driving_data = pandas.read_csv(\"driving.csv\", header=0, usecols=(10, 11, 12))\n",
    "walking_data = pandas.read_csv(\"walking.csv\", header=0, usecols=(10, 11, 12))\n",
    "running_data = pandas.read_csv(\"running.csv\", header=0, usecols=(10, 11, 12))\n",
    "sitting_data = pandas.read_csv(\"static.csv\", header=0, usecols=(10, 11, 12))\n",
    "climbing_data = pandas.read_csv(\"upstair.csv\", header=0, usecols=(10, 11, 12))\n",
    "\n",
    "'''\n",
    "Super huge thank you to Heather for letting me use her data!! I had my own originally,\n",
    "which I recoreded by setting a herd of iPhoned freshmen loose in the Nelson (more efficient\n",
    "lol), but then we found out about the can't-turn-off-your-screen thing, which invalidated\n",
    "all the data.\n",
    "\n",
    "Then I went to record it all myself on my Android using Androsensor, but after I recorded all\n",
    "the data, I found out that accelerometer data didn't record because my phone's gyroscope\n",
    "is broken. This was the moment at which I decided to just ask someone else if I could use their\n",
    "data.\n",
    "'''\n",
    "# ignore this\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This is all just useful information. Thanks for the helpful\n",
    "builtin, pandas! This was helpful in figuring out what my\n",
    "features should be. It's commented out because it's not\n",
    "necessary for the code to run, and it has a long output, but\n",
    "you can un-comment it if you want to see the results. \n",
    "''' \n",
    "1\n",
    "# print(\"--------\")\n",
    "# print(\"driving\")\n",
    "# print(\"--------\")\n",
    "# print(driving_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"walking\")\n",
    "# print(\"--------\")\n",
    "# print(walking_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"running\")\n",
    "# print(\"--------\")\n",
    "# print(running_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"sitting\")\n",
    "# print(\"--------\")\n",
    "# print(sitting_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"climbing\")\n",
    "# print(\"--------\")\n",
    "# print(climbing_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# chunk_data : DataFrame -> listof(DataFrame)\n",
    "# input : data - a DataFrame of length ~30k holding the dataset you want\n",
    "#                to chunk up\n",
    "# output : a list of 30 DataFrames, each DataFrame being 1000 long (except\n",
    "#          for the very last one, which might be missing like 10 points,\n",
    "#          but whatever)\n",
    "def chunk_data(data):\n",
    "    toReturn = []\n",
    "    for i in range(30):\n",
    "        # 975 instead of 1000 bc datasets are a few points short\n",
    "        # this should only cause a trivial difference if any at all\n",
    "        toReturn.append(data[i*975 : (i+1)*975])\n",
    "    return toReturn\n",
    "\n",
    "# chunk the data!\n",
    "driving_chunks = chunk_data(driving_data)\n",
    "sitting_chunks = chunk_data(sitting_data)\n",
    "walking_chunks = chunk_data(walking_data)\n",
    "climbing_chunks = chunk_data(climbing_data)\n",
    "running_chunks = chunk_data(running_data)\n",
    "\n",
    "# shuffle is there because it makes the data more, like, balanced\n",
    "#    --> cause like what if you have random crap at the end\n",
    "random.shuffle(driving_chunks)\n",
    "random.shuffle(sitting_chunks)\n",
    "random.shuffle(walking_chunks)\n",
    "random.shuffle(climbing_chunks)\n",
    "random.shuffle(running_chunks)\n",
    "\n",
    "# get x, y, and z\n",
    "\n",
    "# get_x : listof(DataFrame) -> listof(Series)\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of Series containing only the x-accelerometer\n",
    "#          data from those chunks\n",
    "def get_x(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(chunk[\"user_acc_x\"])\n",
    "    return toReturn\n",
    "\n",
    "# get_y : listof(DataFrame) -> listof(Series)\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of Series containing only the y-accelerometer\n",
    "#          data from those chunks\n",
    "def get_y(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(chunk[\"user_acc_y\"])\n",
    "    return toReturn\n",
    "\n",
    "# get_z : listof(DataFrame) -> listof(Series)\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of Series containing only the z-accelerometer\n",
    "#          data from those chunks\n",
    "def get_z(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(chunk[\"user_acc_z\"])\n",
    "    return toReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# make_feature_chunk : Series -> listof(float)\n",
    "# input : chunk - a Series with ten seconds of data for a single\n",
    "#         activity in one dimension (x, y, or z)\n",
    "# output : a three-element array holding the max, min, and max\n",
    "#          of the fft for the chunk, in that order\n",
    "def make_feature_chunk(chunk):\n",
    "    return [chunk.as_matrix().max(), chunk.as_matrix().mean(), chunk.as_matrix().std()]\n",
    "\n",
    "# extract_features : listof(DataFrame) -> listof(listof(float)))\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of 3-elt lists, where 0th elt is max, 1st is\n",
    "#          mean, 2nd is standard deviation\n",
    "def extract_features(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(make_feature_chunk(chunk))\n",
    "    return toReturn\n",
    "\n",
    "# features_by_plane : listof(DataFrame) -> listof(listof(listof(float)))\n",
    "# input : aloc - list of DataFrame chunks\n",
    "# output : a list of three lists, divvied up by x, y, and z. those lists\n",
    "#          have 30 elts of 3-elt lists, which contain the min & max, in\n",
    "#          that order\n",
    "def features_by_plane(aloc):\n",
    "    return [extract_features(get_x(aloc)), extract_features(get_y(aloc)), extract_features(get_z(aloc))]\n",
    "\n",
    "# make the array with the features!!\n",
    "driving_features = features_by_plane(driving_chunks)\n",
    "sitting_features = features_by_plane(sitting_chunks)\n",
    "walking_features = features_by_plane(walking_chunks)\n",
    "climbing_features = features_by_plane(climbing_chunks)\n",
    "running_features = features_by_plane(running_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_train : listof(listof(listof(float))) -> listof(listof(listof(float)))\n",
    "# input : features - 3-elt list of lists, where 0th is x, 1st is y, and 2nd\n",
    "#         is z. inner list is 30-elts long and has all the chunks\n",
    "#         the chunks are all the features (max, mean, and std)\n",
    "# output : the same data structure, but only the first 24 of the\n",
    "#          thirty chunks\n",
    "def get_train(features):\n",
    "    toReturn = []\n",
    "    for dimension in features:\n",
    "        toReturn.append(dimension[:24])\n",
    "    return toReturn\n",
    "\n",
    "# get_test : listof(listof(listof(float))) -> listof(listof(listof(float)))\n",
    "# input : features - 3-elt list of lists, where 0th is x, 1st is y, and 2nd\n",
    "#         is z. inner list is 30-elts long and has all the chunks\n",
    "#         the chunks are all the features (max, mean, and std)\n",
    "# output : the same data structure, but only the last 6 of the\n",
    "#          thirty chunks\n",
    "def get_test(features):\n",
    "    toReturn = []\n",
    "    for dimension in features:\n",
    "        toReturn.append(dimension[24:])\n",
    "    return toReturn\n",
    "\n",
    "# divvy up the training data / testing data\n",
    "driving_train = get_train(driving_features)\n",
    "driving_test = get_test(driving_features)\n",
    "\n",
    "sitting_train = get_train(sitting_features)\n",
    "sitting_test = get_test(sitting_features)\n",
    "\n",
    "walking_train = get_train(walking_features)\n",
    "walking_test = get_test(walking_features)\n",
    "\n",
    "climbing_train = get_train(climbing_features)\n",
    "climbing_test = get_test(climbing_features)\n",
    "\n",
    "running_train = get_train(running_features)\n",
    "running_test = get_test(running_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate the x, y, and z arrays bc srsly why did i do that\n",
    "\n",
    "# collapse_arr : listof(listof(listof(float))) -> listof(listof(float))\n",
    "# input : data - 3-elt list of lists, where 0th is x, 1st is y, and 2nd is z.\n",
    "#         inner list is 30-elts long and has all the chunks\n",
    "#         the chunks are all the features (max, mean, and std)\n",
    "# output : all the chunks, but not separated by x, y, or z (so it'll\n",
    "#          be all of x, then all of y, then all of z, continously)\n",
    "def collapse_arr(data):\n",
    "    toReturn = []\n",
    "    for plane in data:\n",
    "        for chunk in plane:\n",
    "            toReturn.append(chunk)\n",
    "    return toReturn\n",
    "\n",
    "total_driving_train = collapse_arr(driving_train)\n",
    "total_driving_test = collapse_arr(driving_test)\n",
    "\n",
    "total_sitting_train = collapse_arr(sitting_train)\n",
    "total_sitting_test = collapse_arr(sitting_test)\n",
    "\n",
    "total_walking_train = collapse_arr(walking_train)\n",
    "total_walking_test = collapse_arr(walking_test)\n",
    "\n",
    "total_climbing_train = collapse_arr(climbing_train)\n",
    "total_climbing_test = collapse_arr(climbing_test)\n",
    "\n",
    "total_running_train = collapse_arr(running_train)\n",
    "total_running_test = collapse_arr(running_test)\n",
    "\n",
    "# combine the data\n",
    "all_the_training_data = total_driving_train + total_sitting_train + total_walking_train + total_climbing_train + total_running_train\n",
    "all_the_testing_data = total_driving_test + total_sitting_test + total_walking_test + total_climbing_test + total_running_test\n",
    "    \n",
    "# make_labels : int -> listof(int)\n",
    "# input : n - the number of labels you need\n",
    "#         k - how many instances of each of those labels you need\n",
    "# output : an array with n unique k-length labels\n",
    "# example : make_labels(2, 3) --> [0, 0, 0, 1, 1, 1]\n",
    "def make_labels(n, k):\n",
    "    toReturn = []\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            toReturn.append(i)\n",
    "    return toReturn\n",
    "\n",
    "# make the training labels\n",
    "training_labels = make_labels(5, 72)\n",
    "testing_labels = make_labels(5, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78888888888888886"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now it is time for magic!!!\n",
    "from sklearn import linear_model\n",
    "\n",
    "logistic_regression = linear_model.LogisticRegression()\n",
    "logistic_regression.fit(all_the_training_data, training_labels)\n",
    "# logistic_regression.score(all_the_training_data, training_labels)\n",
    "logistic_regression.score(all_the_testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74444444444444446"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number above is not magic\n",
    "# sad :C\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()\n",
    "svm.fit(all_the_training_data, training_labels)\n",
    "# svm.score(all_the_training_data, training_labels)\n",
    "svm.score(all_the_testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97777777777777775"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neither is that one\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "k_neighbors = neighbors.KNeighborsClassifier()\n",
    "k_neighbors.fit(all_the_training_data, training_labels)\n",
    "# k_neighbors.score(all_the_training_data, training_labels)\n",
    "k_neighbors.score(all_the_testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number above kind of is [magic]!!!\n",
    "\n",
    "'''\n",
    "K-Nearest-Neighbors is definitely the best one here. I suspect this goes back\n",
    "to something we talked about in class (or something I read, can't remember)\n",
    "where we concluded that elaborate equations do not necessarily make a classifier\n",
    "accurate, but instead what makes your algorithm accurate is having a ton of data.\n",
    "In this way, even a relatively simple algorithm (like k-n-n) will do well. The\n",
    "thing that surpises me about that here is that I don't have that much data,\n",
    "so it's not immediately obvious to me why knn worked well in this instance.\n",
    "I also feel like if knn did well, shouldn't logistic regression have done well?\n",
    "They both simple and I feel like you can describe their algorithm as \"well,\n",
    "here's a group... let's draw the line through it.\" So if I had to guess, I\n",
    "would have hypothesized they would have done similarly, but they didn't.\n",
    "\n",
    "Earlier, I attempted fft, and while I wasn't able to get it to work\n",
    "programmatically,  I think finding the max of the fft would have been\n",
    "a good way to approach finding some of the differences. This is because\n",
    "the max would essentially be describing, for example, the space\n",
    "between steps (the cadence of the gait), which is what's going to be one\n",
    "of the biggest differences between the activities (especially running and\n",
    "walking).\n",
    "\n",
    "If I had gotten fft to work, I also would have used it to approach the bonus\n",
    "problem. The way I would have done that is by collecting my breathing data,\n",
    "then running it thorugh fft. Theoretically, I'd get a result that looks something\n",
    "like this:\n",
    "\n",
    "^\n",
    "|\n",
    "|              __\n",
    "|             /  \\\n",
    "|            /    \\\n",
    "|   __      /      \\\n",
    "|  /  \\    /        \\\n",
    "|_/    \\__/          \\_______>\n",
    "|___________________________________>\n",
    "\n",
    "Now, before even using this, we could assume a two things:\n",
    "a) my heartrate is faster than my respiratory rate\n",
    "b) breathing makes my chest rise more than my heart beating does\n",
    "\n",
    "With these assumptions in mind, we could look at the result of this fft\n",
    "and note that the first bump, which is high frequency and low amplitude,\n",
    "probably is the heartrate. Thus the larger bump, which is lower frequency\n",
    "and higher amplitude (to be honest I don't totally understand what the y-axis\n",
    "for the result of an fft is, but we know that the bigger your bump is on the\n",
    "y-dimension, the bigger the movement probably was), is probably my\n",
    "respiratory rate.\n",
    "\n",
    "This assignment was fun! My midnight Slack struggles probably didn't indicate\n",
    "as much, but doing ML for the first time made me feel like a ~*~real\n",
    "computer scientist~*~.\n",
    "\n",
    "'''\n",
    "# this is so my text doesn't get printed below cause that's ugly\n",
    "# I know I could have used Markdown, but I tried it and it did not adhere\n",
    "# to my aesthetic\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
