{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# import CSV files as DataFrames\n",
    "driving_data = pandas.read_csv(\"driving.csv\", header=0, usecols=(10, 11, 12))\n",
    "walking_data = pandas.read_csv(\"walking.csv\", header=0, usecols=(10, 11, 12))\n",
    "running_data = pandas.read_csv(\"running.csv\", header=0, usecols=(10, 11, 12))\n",
    "sitting_data = pandas.read_csv(\"static.csv\", header=0, usecols=(10, 11, 12))\n",
    "climbing_data = pandas.read_csv(\"upstair.csv\", header=0, usecols=(10, 11, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to ML (in order)\n",
    "====================\n",
    "\n",
    "1. find features\n",
    "   ..* max of fft\n",
    "2. classify on those features using built-in ML functions\n",
    "3. do the test data --> machine guessed right? 1/1. machine guessed wrong? 1/2.\n",
    "4. rejoice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is all just useful information. Thanks for the helpful\n",
    "# builtin, pandas! This was helpful in figuring out what my\n",
    "# features should be. It's commented out because it's not\n",
    "# necessary for the code to run, and it has a long output, but\n",
    "# you can un-comment it if you want to see the results.\n",
    "\n",
    "# print(\"--------\")\n",
    "# print(\"driving\")\n",
    "# print(\"--------\")\n",
    "# print(driving_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"walking\")\n",
    "# print(\"--------\")\n",
    "# print(walking_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"running\")\n",
    "# print(\"--------\")\n",
    "# print(running_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"sitting\")\n",
    "# print(\"--------\")\n",
    "# print(sitting_data.describe())\n",
    "# print(\"--------\")\n",
    "# print(\"climbing\")\n",
    "# print(\"--------\")\n",
    "# print(climbing_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# chunk_data : DataFrame -> listof(DataFrame)\n",
    "# input : data - a DataFrame of length ~30k holding the dataset you want\n",
    "#                to chunk up\n",
    "# output : a list of 30 DataFrames, each DataFrame being 1000 long (except\n",
    "#          for the very last one, which might be missing like 10 points,\n",
    "#          but whatever)\n",
    "def chunk_data(data):\n",
    "    toReturn = []\n",
    "    for i in range(30):\n",
    "        toReturn.append(data[i*975 : (i+1)*975])\n",
    "    return toReturn\n",
    "\n",
    "# chunk the data!\n",
    "driving_chunks = chunk_data(driving_data)\n",
    "sitting_chunks = chunk_data(sitting_data)\n",
    "walking_chunks = chunk_data(walking_data)\n",
    "climbing_chunks = chunk_data(climbing_data)\n",
    "running_chunks = chunk_data(running_data)\n",
    "\n",
    "# shuffle is there because it makes the data more, like, balanced\n",
    "#    --> cause like what if you have random crap at the end\n",
    "random.shuffle(driving_chunks)\n",
    "random.shuffle(sitting_chunks)\n",
    "random.shuffle(walking_chunks)\n",
    "random.shuffle(climbing_chunks)\n",
    "random.shuffle(running_chunks)\n",
    "\n",
    "# get x, y, and z\n",
    "\n",
    "# get_x : listof(DataFrame) -> listof(Series)\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of Series containing only the x-accelerometer\n",
    "#          data from those chunks\n",
    "def get_x(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(chunk[\"user_acc_x\"])\n",
    "    return toReturn\n",
    "\n",
    "# get_y : listof(DataFrame) -> listof(Series)\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of Series containing only the y-accelerometer\n",
    "#          data from those chunks\n",
    "def get_y(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(chunk[\"user_acc_y\"])\n",
    "    return toReturn\n",
    "\n",
    "# get_z : listof(DataFrame) -> listof(Series)\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of Series containing only the z-accelerometer\n",
    "#          data from those chunks\n",
    "def get_z(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(chunk[\"user_acc_z\"])\n",
    "    return toReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# make_feature_chunk : Series -> listof(float)\n",
    "# input : chunk - a Series with ten seconds of data for a single\n",
    "#         activity in one dimension (x, y, or z)\n",
    "# output : a three-element array holding the max, min, and max\n",
    "#          of the fft for the chunk, in that order\n",
    "def make_feature_chunk(chunk):\n",
    "    return [chunk.as_matrix().max(), chunk.as_matrix().mean(), chunk.as_matrix().std()]\n",
    "\n",
    "# extract_features : listof(DataFrame) -> listof(listof(float)))\n",
    "# input : aloc - a list of DataFrame chunks\n",
    "# output : a list of 3-elt lists, where 0th elt is max, 1st is\n",
    "#          mean, 2nd is standard deviation\n",
    "def extract_features(aloc):\n",
    "    toReturn = []\n",
    "    for chunk in aloc:\n",
    "        toReturn.append(make_feature_chunk(chunk))\n",
    "    return toReturn\n",
    "\n",
    "# features_by_plane : listof(DataFrame) -> listof(listof(listof(float)))\n",
    "# input : aloc - list of DataFrame chunks\n",
    "# output : a list of three lists, divvied up by x, y, and z. those lists\n",
    "#          have 30 elts of 3-elt lists, which contain the min & max, in\n",
    "#          that order\n",
    "def features_by_plane(aloc):\n",
    "    return [extract_features(get_x(aloc)), extract_features(get_y(aloc)), extract_features(get_z(aloc))]\n",
    "\n",
    "# make the array with the features!!\n",
    "driving_features = features_by_plane(driving_chunks)\n",
    "sitting_features = features_by_plane(sitting_chunks)\n",
    "walking_features = features_by_plane(walking_chunks)\n",
    "climbing_features = features_by_plane(climbing_chunks)\n",
    "running_features = features_by_plane(running_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_train : listof(listof(listof(float))) -> listof(listof(listof(float)))\n",
    "# input : features - 3-elt list of lists, where 0th is x, 1st is y, and 2nd\n",
    "#         is z. inner list is 30-elts long and has all the chunks\n",
    "#         the chunks are all the features (max, mean, and std)\n",
    "# output : the same data structure, but only the first 24 of the\n",
    "#          thirty chunks\n",
    "def get_train(features):\n",
    "    toReturn = []\n",
    "    for dimension in features:\n",
    "        toReturn.append(dimension[:24])\n",
    "    return toReturn\n",
    "\n",
    "# get_test : listof(listof(listof(float))) -> listof(listof(listof(float)))\n",
    "# input : features - 3-elt list of lists, where 0th is x, 1st is y, and 2nd\n",
    "#         is z. inner list is 30-elts long and has all the chunks\n",
    "#         the chunks are all the features (max, mean, and std)\n",
    "# output : the same data structure, but only the last 6 of the\n",
    "#          thirty chunks\n",
    "def get_test(features):\n",
    "    toReturn = []\n",
    "    for dimension in features:\n",
    "        toReturn.append(dimension[24:])\n",
    "    return toReturn\n",
    "\n",
    "# divvy up the training data / testing data\n",
    "driving_train = get_train(driving_features)\n",
    "driving_test = get_test(driving_features)\n",
    "\n",
    "sitting_train = get_train(sitting_features)\n",
    "sitting_test = get_test(sitting_features)\n",
    "\n",
    "walking_train = get_train(walking_features)\n",
    "walking_test = get_test(walking_features)\n",
    "\n",
    "climbing_train = get_train(climbing_features)\n",
    "climbing_test = get_test(climbing_features)\n",
    "\n",
    "running_train = get_train(running_features)\n",
    "running_test = get_test(running_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate the x, y, and z arrays bc srsly why did i do that\n",
    "\n",
    "# collapse_arr : listof(listof(listof(float))) -> listof(listof(float))\n",
    "# input : data - 3-elt list of lists, where 0th is x, 1st is y, and 2nd is z.\n",
    "#         inner list is 30-elts long and has all the chunks\n",
    "#         the chunks are all the features (max, mean, and std)\n",
    "# output : all the chunks, but not separated by x, y, or z (so it'll\n",
    "#          be all of x, then all of y, then all of z, continously)\n",
    "def collapse_arr(data):\n",
    "    toReturn = []\n",
    "    for plane in data:\n",
    "        for chunk in plane:\n",
    "            toReturn.append(chunk)\n",
    "    return toReturn\n",
    "\n",
    "total_driving_train = collapse_arr(driving_train)\n",
    "total_driving_test = collapse_arr(driving_test)\n",
    "\n",
    "total_sitting_train = collapse_arr(sitting_train)\n",
    "total_sitting_test = collapse_arr(sitting_test)\n",
    "\n",
    "total_walking_train = collapse_arr(walking_train)\n",
    "total_walking_test = collapse_arr(walking_test)\n",
    "\n",
    "total_climbing_train = collapse_arr(climbing_train)\n",
    "total_climbing_test = collapse_arr(climbing_test)\n",
    "\n",
    "total_running_train = collapse_arr(running_train)\n",
    "total_running_test = collapse_arr(running_test)\n",
    "\n",
    "# combine the data\n",
    "all_the_training_data = total_driving_train + total_sitting_train + total_walking_train + total_climbing_train + total_running_train\n",
    "all_the_testing_data = total_driving_test + total_sitting_test + total_walking_test + total_climbing_test + total_running_test\n",
    "    \n",
    "# make_labels : int -> listof(int)\n",
    "# input : n - the number of labels you need\n",
    "#         k - how many instances of each of those labels you need\n",
    "# output : an array with n unique k-length labels\n",
    "# example : make_labels(2, 3) --> [0, 0, 0, 1, 1, 1]\n",
    "def make_labels(n, k):\n",
    "    toReturn = []\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            toReturn.append(i)\n",
    "    return toReturn\n",
    "\n",
    "# make the training labels\n",
    "training_labels = make_labels(5, 72)\n",
    "testing_labels = make_labels(5, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82222222222222219"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for the fun part!!\n",
    "from sklearn import linear_model\n",
    "\n",
    "logistic_regression = linear_model.LogisticRegression()\n",
    "logistic_regression.fit(all_the_training_data, training_labels)\n",
    "logistic_regression.score(all_the_testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75555555555555554"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC()\n",
    "svm.fit(all_the_training_data, training_labels)\n",
    "# svm.score(all_the_training_data, training_labels)\n",
    "svm.score(all_the_testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95833333333333337"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "k_neighbors = neighbors.KNeighborsClassifier()\n",
    "k_neighbors.fit(all_the_training_data, training_labels)\n",
    "# k_neighbors.score(all_the_training_data, training_labels)\n",
    "k_neighbors.score(all_the_testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
